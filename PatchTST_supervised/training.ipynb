{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9340fe8e-77c5-4de7-bcd4-0b9c7c23f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
    "import argparse\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bfafc9-3c8b-45e8-b0cb-1a5c37466886",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 3000\n",
    "num_features = 10\n",
    "pred_len = 60\n",
    "label_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b64a65-f55c-497a-8175-22329c7ee7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.uniform(low=1, high=100, size=(time_steps, num_features))\n",
    "data_y = data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b0e9b1-bcdd-47ea-bef3-09fd0ce71ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 10), (3000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04a49a9-da33-42d3-84cf-24d3fd94f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d98238d-3ffc-4d6c-a85c-cb7981ae63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPretrainDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, num_features, time_steps=15, seq_len=96, pred_len=96, label_len=48, bs=5):\n",
    "        self.num_features = num_features\n",
    "        self.time_steps = time_steps\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.label_len = label_len\n",
    "        self.batch_size = bs\n",
    "        self.prebatch_len = seq_len + bs  - 1\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.time_steps - self.seq_len - pred_len + 1) // self.batch_size \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s_begin = self.batch_size * idx\n",
    "        s_end = s_begin + self.prebatch_len \n",
    "        # r_begin = s_end - 1 # - self.label_len\n",
    "        # r_end = r_begin + 1 # + self.pred_len  + self.label_len \n",
    "        #regression\n",
    "        # r_begin = s_begin + self.seq_len - 1\n",
    "        # r_end = r_begin + self.batch_size\n",
    "        \n",
    "        r_begin = s_begin + self.seq_len - self.label_len -1\n",
    "        r_end = r_begin + self.pred_len + self.label_len + self.batch_size - 1\n",
    "        # print(s_begin, s_end, r_begin, r_end)\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return torch.Tensor(seq_x).to(device), torch.Tensor(seq_y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d047a7a-3ef0-41d7-872c-e2ef0932d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = DummyPretrainDataset(data_x, data_y, num_features, time_steps, seq_len=500, pred_len=pred_len, label_len=label_len, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6d8b55-e85c-4a03-aa1e-65e3196a0dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([599, 10]), torch.Size([199, 10]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0][0].shape, dset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061eceab-9987-4e6f-a1d9-487fa816cfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69d2cba2-cdb6-41c1-a4c1-a8cbc985580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n",
      "torch.Size([599, 100]) torch.Size([199, 100])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dset)) :\n",
    "    print(dset[i][0].shape, dset[i][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c610b2-2621-421e-9b39-b54dcd05b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowView:\n",
    "    def __init__(self, window_size, stride, pred_len, label_len):\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.pred_len = pred_len\n",
    "        self.label_len = label_len\n",
    "    def slide_collate_fn(self, batch):\n",
    "        return batch[0].unfold(0, self.window_size, self.stride).transpose(1,2), batch[1].unfold(0, self.pred_len+self.label_len, self.stride).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7a1d2a-5bea-4da7-9d6b-16b7ff2acacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindowView(500, 1, pred_len, label_len)\n",
    "w_dl = DataLoader(dset, batch_size=None, collate_fn=sw.slide_collate_fn, pin_memory=False)\n",
    "# start = time.time()\n",
    "# for b in w_dl:\n",
    "#     # b1=b\n",
    "#     print(b[0].shape, b[1].shape)\n",
    "#     # print(b)\n",
    "# stop = time.time()\n",
    "# print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9fad07-0407-4277-837f-5f4f2765d2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ee031-e1fb-4b55-a941-800efa6081ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892dfb6-637d-47f7-b18b-8ad362f96706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "de2c0111-2f7a-46f6-a56f-1a5b21d961a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36df48a4-65a7-4b57-91ed-7674fe1f2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPretrainStackDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, num_features, time_steps=15, seq_len=6, pred_len=8, label_len=8, bs=5):\n",
    "        self.num_features = num_features\n",
    "        self.time_steps = time_steps\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.label_len = label_len\n",
    "        # self.batch_size = bs\n",
    "        # self.prebatch_len = seq_len + bs - 1\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.time_steps - self.seq_len + 1 - self.pred_len)  # // self.batch_size \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s_begin = idx\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin  + self.pred_len  + self.label_len \n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return torch.Tensor(seq_x), torch.Tensor(seq_y)\n",
    "# b1[0].float(), b1[0][:,:,:4].float(), dec_inp, b1[1][:,:,:4].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8af49fe-1684-4ecd-9657-3a767d450e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sset = DummyPretrainStackDataset(data_x, data_y, num_features, time_steps, seq_len=500, pred_len=60, label_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d87dd95-fffa-4a35-8eaf-6f110136e7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e82eab5-0b3f-4c1b-ae29-d48c21ee751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4070cfdf-3e00-4ccc-842e-96ea3273e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dl = DataLoader(sset, batch_size=100, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4595e46-3fa5-4225-b539-3a168b745405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "981e8597-3cb4-47ff-8c99-b5b8347b2d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "torch.Size([100, 500, 100]) torch.Size([100, 100, 100])\n",
      "0.8885679244995117\n"
     ]
    }
   ],
   "source": [
    "b1 = None\n",
    "start = time.time()\n",
    "for b in s_dl:\n",
    "    # b1=b\n",
    "    print(b[0].shape, b[1].shape)\n",
    "    # print(b)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd75a1e3-2f0b-4dec-b048-e07d1c2e9f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[89.7994, 55.5096, 37.7528,  ..., 62.6079, 44.4679, 15.7314],\n",
       "          [83.1737, 83.9626, 77.8187,  ..., 85.2087, 42.3049, 77.4481],\n",
       "          [95.6394, 71.6739, 79.2538,  ..., 57.0945, 21.0284, 38.3425],\n",
       "          ...,\n",
       "          [43.1796, 84.0346, 25.3106,  ..., 53.3819,  8.5694, 67.5977],\n",
       "          [60.1137, 92.2419,  2.5538,  ..., 65.1549, 55.2438, 92.0792],\n",
       "          [36.3255, 45.5186, 31.7847,  ..., 68.4275, 11.2777, 17.1702]],\n",
       " \n",
       "         [[83.1737, 83.9626, 77.8187,  ..., 85.2087, 42.3049, 77.4481],\n",
       "          [95.6394, 71.6739, 79.2538,  ..., 57.0945, 21.0284, 38.3425],\n",
       "          [17.7794,  1.4215, 12.2500,  ..., 91.0731, 43.1982, 10.1609],\n",
       "          ...,\n",
       "          [60.1137, 92.2419,  2.5538,  ..., 65.1549, 55.2438, 92.0792],\n",
       "          [36.3255, 45.5186, 31.7847,  ..., 68.4275, 11.2777, 17.1702],\n",
       "          [ 8.5127, 96.7749, 56.4547,  ..., 13.9612, 23.4854, 81.9528]],\n",
       " \n",
       "         [[95.6394, 71.6739, 79.2538,  ..., 57.0945, 21.0284, 38.3425],\n",
       "          [17.7794,  1.4215, 12.2500,  ..., 91.0731, 43.1982, 10.1609],\n",
       "          [48.0110, 70.8887, 53.3025,  ..., 24.7458, 22.8693, 70.5356],\n",
       "          ...,\n",
       "          [36.3255, 45.5186, 31.7847,  ..., 68.4275, 11.2777, 17.1702],\n",
       "          [ 8.5127, 96.7749, 56.4547,  ..., 13.9612, 23.4854, 81.9528],\n",
       "          [28.2864, 94.8681, 87.3054,  ..., 38.4815, 31.0258, 89.8600]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[10.5206, 25.3790, 47.0758,  ..., 12.4741, 48.0290,  4.8917],\n",
       "          [88.1680, 44.2230, 69.0863,  ..., 77.8108,  8.4575, 55.1573],\n",
       "          [40.5863, 84.9343,  7.4932,  ..., 60.5688, 20.6565, 62.0699],\n",
       "          ...,\n",
       "          [86.2889, 44.9965, 72.1454,  ..., 97.9379, 91.8442, 94.3893],\n",
       "          [52.4714, 93.0604, 77.0868,  ..., 49.6998, 10.9958, 47.1147],\n",
       "          [18.6756, 73.9225, 73.8732,  ..., 81.1988, 88.7249, 26.3960]],\n",
       " \n",
       "         [[88.1680, 44.2230, 69.0863,  ..., 77.8108,  8.4575, 55.1573],\n",
       "          [40.5863, 84.9343,  7.4932,  ..., 60.5688, 20.6565, 62.0699],\n",
       "          [29.5384, 16.6765, 88.6906,  ..., 60.4916, 59.9863, 57.9124],\n",
       "          ...,\n",
       "          [52.4714, 93.0604, 77.0868,  ..., 49.6998, 10.9958, 47.1147],\n",
       "          [18.6756, 73.9225, 73.8732,  ..., 81.1988, 88.7249, 26.3960],\n",
       "          [46.0043, 42.7623, 60.5424,  ...,  3.4194, 14.5159, 45.2598]],\n",
       " \n",
       "         [[40.5863, 84.9343,  7.4932,  ..., 60.5688, 20.6565, 62.0699],\n",
       "          [29.5384, 16.6765, 88.6906,  ..., 60.4916, 59.9863, 57.9124],\n",
       "          [42.3315, 60.4427, 19.0247,  ..., 87.9869, 20.1186, 92.1525],\n",
       "          ...,\n",
       "          [18.6756, 73.9225, 73.8732,  ..., 81.1988, 88.7249, 26.3960],\n",
       "          [46.0043, 42.7623, 60.5424,  ...,  3.4194, 14.5159, 45.2598],\n",
       "          [52.4195, 44.6975, 27.7555,  ..., 57.3378, 27.0356, 98.3659]]]),\n",
       " tensor([[[76.1554, 12.8640,  3.0868,  ..., 11.8020, 36.2812, 83.8337],\n",
       "          [37.9988, 93.9743, 72.7434,  ..., 85.8203, 52.3496, 27.7426],\n",
       "          [95.1282, 15.1638, 54.1558,  ...,  6.8170, 46.8368, 12.5485],\n",
       "          ...,\n",
       "          [ 1.8656,  5.8448, 23.0873,  ..., 17.2544, 69.6772, 20.9286],\n",
       "          [31.4875, 74.0697,  6.4331,  ..., 84.2965, 43.1544, 18.0745],\n",
       "          [42.3165, 50.4681, 28.2390,  ..., 79.3914, 55.3207, 54.9238]],\n",
       " \n",
       "         [[37.9988, 93.9743, 72.7434,  ..., 85.8203, 52.3496, 27.7426],\n",
       "          [95.1282, 15.1638, 54.1558,  ...,  6.8170, 46.8368, 12.5485],\n",
       "          [26.0600,  3.9188, 82.2565,  ...,  6.0333, 20.6355, 17.4012],\n",
       "          ...,\n",
       "          [31.4875, 74.0697,  6.4331,  ..., 84.2965, 43.1544, 18.0745],\n",
       "          [42.3165, 50.4681, 28.2390,  ..., 79.3914, 55.3207, 54.9238],\n",
       "          [68.8321, 22.9764, 82.2443,  ..., 36.9700, 25.6801, 77.5214]],\n",
       " \n",
       "         [[95.1282, 15.1638, 54.1558,  ...,  6.8170, 46.8368, 12.5485],\n",
       "          [26.0600,  3.9188, 82.2565,  ...,  6.0333, 20.6355, 17.4012],\n",
       "          [77.0084, 70.4209, 48.8772,  ...,  7.2499, 45.4093, 90.7123],\n",
       "          ...,\n",
       "          [42.3165, 50.4681, 28.2390,  ..., 79.3914, 55.3207, 54.9238],\n",
       "          [68.8321, 22.9764, 82.2443,  ..., 36.9700, 25.6801, 77.5214],\n",
       "          [15.6592, 27.4612, 32.7689,  ..., 97.3989, 84.8159, 38.6176]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.8656,  5.8448, 23.0873,  ..., 17.2544, 69.6772, 20.9286],\n",
       "          [31.4875, 74.0697,  6.4331,  ..., 84.2965, 43.1544, 18.0745],\n",
       "          [42.3165, 50.4681, 28.2390,  ..., 79.3914, 55.3207, 54.9238],\n",
       "          ...,\n",
       "          [97.0173, 48.3535, 94.1368,  ...,  9.7209, 77.2120, 31.5410],\n",
       "          [76.2194, 51.1197, 13.5470,  ..., 49.4790, 64.5211,  5.1213],\n",
       "          [60.5059,  3.5476, 55.8031,  ..., 35.5190, 66.3913, 47.2899]],\n",
       " \n",
       "         [[31.4875, 74.0697,  6.4331,  ..., 84.2965, 43.1544, 18.0745],\n",
       "          [42.3165, 50.4681, 28.2390,  ..., 79.3914, 55.3207, 54.9238],\n",
       "          [68.8321, 22.9764, 82.2443,  ..., 36.9700, 25.6801, 77.5214],\n",
       "          ...,\n",
       "          [76.2194, 51.1197, 13.5470,  ..., 49.4790, 64.5211,  5.1213],\n",
       "          [60.5059,  3.5476, 55.8031,  ..., 35.5190, 66.3913, 47.2899],\n",
       "          [45.1220, 63.4496, 16.0342,  ..., 98.7507,  5.5285, 23.7297]],\n",
       " \n",
       "         [[42.3165, 50.4681, 28.2390,  ..., 79.3914, 55.3207, 54.9238],\n",
       "          [68.8321, 22.9764, 82.2443,  ..., 36.9700, 25.6801, 77.5214],\n",
       "          [15.6592, 27.4612, 32.7689,  ..., 97.3989, 84.8159, 38.6176],\n",
       "          ...,\n",
       "          [60.5059,  3.5476, 55.8031,  ..., 35.5190, 66.3913, 47.2899],\n",
       "          [45.1220, 63.4496, 16.0342,  ..., 98.7507,  5.5285, 23.7297],\n",
       "          [45.9271, 18.0085, 40.5567,  ..., 13.5428, 73.0676, 70.5161]]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9493ba-5f64-4346-bcd9-1ec2a65281f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5eb9328b-547c-437a-a597-625292d54176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18e7b55-0e4c-4b0d-a136-9b9fe6470304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(random_seed=2021, root_path='./data/ETT/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=500, label_len=40, pred_len=60, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=10, dec_in=10, c_out=10, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=100, patience=100, learning_rate=0.0001, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# random seed\n",
    "parser.add_argument('--random_seed', type=int, default=2021, help='random seed')\n",
    "\n",
    "# # basic config\n",
    "# parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
    "# parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
    "# parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
    "#                     help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# # data loader\n",
    "# parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=500, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=label_len, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=pred_len, help='prediction sequence length')\n",
    "\n",
    "\n",
    "# DLinear\n",
    "#parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "\n",
    "# PatchTST\n",
    "parser.add_argument('--fc_dropout', type=float, default=0.05, help='fully connected dropout')\n",
    "parser.add_argument('--head_dropout', type=float, default=0.0, help='head dropout')\n",
    "parser.add_argument('--patch_len', type=int, default=16, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "parser.add_argument('--padding_patch', default='end', help='None: None; end: padding on the end')\n",
    "parser.add_argument('--revin', type=int, default=1, help='RevIN; True 1 False 0')\n",
    "parser.add_argument('--affine', type=int, default=0, help='RevIN-affine; True 1 False 0')\n",
    "parser.add_argument('--subtract_last', type=int, default=0, help='0: subtract mean; 1: subtract last')\n",
    "parser.add_argument('--decomposition', type=int, default=0, help='decomposition; True 1 False 0')\n",
    "parser.add_argument('--kernel_size', type=int, default=25, help='decomposition-kernel')\n",
    "parser.add_argument('--individual', type=int, default=0, help='individual head; True 1 False 0')\n",
    "\n",
    "# Formers \n",
    "parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
    "parser.add_argument('--enc_in', type=int, default=num_features, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "parser.add_argument('--dec_in', type=int, default=num_features, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=num_features, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=100, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=100, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=100, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type3', help='adjust learning rate')\n",
    "parser.add_argument('--pct_start', type=float, default=0.3, help='pct_start')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "import random\n",
    "# random seed\n",
    "fix_seed = args.random_seed\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d1d028bb-4d3b-4685-8a4e-3a0a3141534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatchTST.Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f9f72f9-6cfa-404b-b407-233f3ed1f752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (revin_layer): RevIN()\n",
       "    (padding_patch_layer): ReplicationPad1d((0, 8))\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (1): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.05, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.05, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.05, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=31744, out_features=60, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "992f2ef3-0f5e-4115-a975-cdea51ca45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 s, sys: 11.8 s, total: 33.1 s\n",
      "Wall time: 6.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[45.9229, 57.0467, 77.3513,  ..., 51.3055, 46.1809, 32.4994],\n",
       "         [40.8363, 57.9277, 32.6596,  ..., 64.3457, 92.9502, 67.7267],\n",
       "         [40.5203, 29.9339, 45.7296,  ..., 48.6110, 19.4358, 71.8770],\n",
       "         ...,\n",
       "         [39.0498, 36.0480, 24.8613,  ..., 44.9997, 23.3362, 72.1767],\n",
       "         [50.2753, 49.1318, 70.6954,  ..., 50.0445, 32.8113, 42.3876],\n",
       "         [58.6064, 61.5207, 56.2034,  ..., 59.1819, 28.4290, 34.1345]],\n",
       "\n",
       "        [[33.4626, 54.7675, 54.2221,  ..., 30.5864, 40.0469, 50.1327],\n",
       "         [65.7028, 73.1609, 67.0423,  ..., 68.4425, 45.4227, 44.8203],\n",
       "         [67.0513, 53.0351, 45.8740,  ..., 51.6351, 56.4419, 55.4173],\n",
       "         ...,\n",
       "         [70.8667, 40.1428, 42.9904,  ..., 50.4454, 68.2771, 53.5072],\n",
       "         [51.1248, 40.6587, 81.4305,  ..., 69.9589, 82.5561, 54.9705],\n",
       "         [24.2019, 50.2997, 38.0113,  ..., 33.3528, 47.5281, 32.6483]],\n",
       "\n",
       "        [[43.8000, 42.0806, 45.8512,  ..., 88.0275, 28.4356, 69.5016],\n",
       "         [39.3049, 39.6446, 42.8704,  ..., 44.6179, 34.5497, 35.9548],\n",
       "         [31.6217, 43.8249, 56.0209,  ..., 58.2568, 66.5284, 44.2496],\n",
       "         ...,\n",
       "         [24.2516, 61.2107, 38.8113,  ..., 64.1565, 49.5030, 62.8794],\n",
       "         [65.3053, 47.0346, 41.8436,  ..., 52.1142, 79.0712, 63.4996],\n",
       "         [68.8196, 73.9749, 47.0853,  ..., 47.5463, 23.3079, 48.8541]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[46.0647, 49.4103, 47.8516,  ..., 68.5906, 45.9160, 46.7571],\n",
       "         [46.1549, 70.8147, 78.5933,  ..., 40.6530, 47.8926,  6.2007],\n",
       "         [35.7146, 54.7658, 52.9665,  ..., 66.8786, 54.4320, 56.5638],\n",
       "         ...,\n",
       "         [28.6391, 53.2759, 76.5410,  ..., 36.1283, 56.5113, 41.3001],\n",
       "         [50.6630, 58.4796, 16.8771,  ..., 74.2017, 50.2656, 44.0440],\n",
       "         [63.2509, 19.7403, 26.7679,  ..., 68.2396, 54.2788, 71.2694]],\n",
       "\n",
       "        [[56.7633, 53.2476, 35.6820,  ..., 68.0070, 64.0480, 41.0059],\n",
       "         [68.6397, 70.1384, 52.2881,  ..., 66.8195,  8.6054, 59.2019],\n",
       "         [55.0106, 54.4084, 55.5395,  ..., 79.1013, 52.6769, 61.2974],\n",
       "         ...,\n",
       "         [48.8563, 75.8389, 43.3191,  ..., 74.1214, 19.4378, 49.7066],\n",
       "         [41.2684, 56.8322, 58.4551,  ..., 93.8592, 43.1463, 54.6325],\n",
       "         [47.7348, 52.9064, 67.2796,  ..., 42.1403, 37.5112, 58.8382]],\n",
       "\n",
       "        [[ 4.0446, 20.0166, 51.8281,  ..., 44.8786, 38.7667, 37.3560],\n",
       "         [46.3873, 42.6592, 56.5031,  ..., 84.5049, 64.5366, 88.2969],\n",
       "         [52.9593, 40.9547, 35.6781,  ..., 47.0060, 34.2232, 57.9113],\n",
       "         ...,\n",
       "         [82.5340, 86.2529, 43.1345,  ..., 39.6225, 50.9469, 48.5357],\n",
       "         [29.6111, 40.7004, 48.7685,  ..., 47.9099, 54.8820, 56.7796],\n",
       "         [53.9974, 89.4927, 49.0153,  ..., 70.4498, 64.0247, 45.1302]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model(b1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "eea7f538-c981-451c-a248-e12aa18e9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DLinear.Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "4cb7815a-1eca-4093-aad2-cc70695c89c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (decompsition): series_decomp(\n",
       "    (moving_avg): moving_avg(\n",
       "      (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "    )\n",
       "  )\n",
       "  (Linear_Seasonal): Linear(in_features=500, out_features=60, bias=True)\n",
       "  (Linear_Trend): Linear(in_features=500, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "1805c140-fac4-4051-86bd-1c024763973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7165e+01,  9.3340e+00, -3.3945e-01,  ...,  4.2045e+00,\n",
       "           3.2258e+01, -8.2107e+00],\n",
       "         [-3.8288e+01, -3.9523e+01,  1.6036e+01,  ..., -2.7061e+01,\n",
       "          -1.4023e+01, -2.4650e+01],\n",
       "         [ 5.5282e-01, -4.6020e+00, -2.2652e+01,  ..., -1.6415e+00,\n",
       "           7.8541e-01, -1.5511e+01],\n",
       "         ...,\n",
       "         [-3.7269e+01,  1.6553e+00, -3.3242e+01,  ...,  2.2123e+00,\n",
       "          -4.3733e+01, -3.8620e+01],\n",
       "         [-5.4318e+01, -7.2704e+00, -9.4540e+00,  ..., -5.2228e+01,\n",
       "          -4.0321e+01, -3.7331e+00],\n",
       "         [ 1.6410e+01,  1.8340e+01, -7.5531e-01,  ..., -1.7320e+01,\n",
       "          -3.3644e+01,  1.4176e+01]],\n",
       "\n",
       "        [[ 2.1554e+01,  9.6288e-01,  1.2074e+01,  ...,  6.5817e+00,\n",
       "           2.0214e+01,  4.2867e-01],\n",
       "         [-9.3766e+00, -6.3090e+00, -3.0387e+01,  ..., -9.2536e+00,\n",
       "          -3.4545e+01, -3.3312e+01],\n",
       "         [-3.8409e+00, -1.7512e+01, -3.7807e+00,  ..., -5.9622e+00,\n",
       "          -4.4367e+00,  6.2254e+00],\n",
       "         ...,\n",
       "         [-8.5296e-01, -2.1392e+01, -8.9140e+00,  ..., -1.2082e+00,\n",
       "           4.0808e+01, -1.9861e+01],\n",
       "         [-3.1222e+01, -2.4195e+01,  2.9859e+00,  ..., -2.9728e+00,\n",
       "          -2.4170e+01, -3.7064e+01],\n",
       "         [ 3.4534e+01, -1.7971e+01,  4.6662e+01,  ..., -1.0315e+01,\n",
       "           1.6067e+00,  1.5280e+01]],\n",
       "\n",
       "        [[ 2.2373e+01,  2.1068e+01, -4.0363e+00,  ...,  1.4276e+01,\n",
       "          -1.0414e+01,  5.8529e+00],\n",
       "         [-3.4337e+01, -4.2993e+01, -2.0318e+01,  ..., -4.8855e+01,\n",
       "          -1.9034e+01, -4.2299e+01],\n",
       "         [ 4.0106e+00,  1.6437e+01, -3.1023e+01,  ...,  1.6950e+01,\n",
       "          -1.2690e+01,  1.0472e+01],\n",
       "         ...,\n",
       "         [-1.6318e+01, -2.0180e+01,  2.4339e+00,  ...,  6.4383e+00,\n",
       "           1.5640e+01, -2.2002e+01],\n",
       "         [ 2.9271e+00, -2.2863e+01, -5.9895e+00,  ..., -2.2467e+01,\n",
       "          -3.2131e+01,  2.0981e+00],\n",
       "         [ 2.6369e+00, -3.8874e+00,  4.1579e+01,  ...,  6.7299e+00,\n",
       "           2.7571e+01,  1.2217e+01]],\n",
       "\n",
       "        [[ 1.7531e+01,  1.7061e+01,  1.8783e+01,  ..., -3.6902e+00,\n",
       "           1.1241e+00,  4.8202e+01],\n",
       "         [-8.3166e+00, -2.3486e+01, -3.2043e+01,  ..., -4.5588e+01,\n",
       "          -3.6606e+01, -1.2555e+01],\n",
       "         [-9.9524e+00, -5.7854e+00,  4.3033e+00,  ...,  1.4137e+01,\n",
       "          -1.5980e+01,  1.7390e+01],\n",
       "         ...,\n",
       "         [-1.6543e+00, -3.3333e+01, -1.5355e+01,  ...,  1.2240e+00,\n",
       "           2.6808e+01, -1.5078e+01],\n",
       "         [-1.7902e+01, -7.5522e+00, -4.1883e+01,  ...,  2.1915e+01,\n",
       "          -2.8740e+01, -5.2062e+01],\n",
       "         [ 2.5838e+01,  1.3550e+01,  2.7227e+00,  ...,  2.5567e+00,\n",
       "           3.0502e+00, -2.4575e+01]],\n",
       "\n",
       "        [[-4.3138e+00,  4.0547e+01,  2.5597e+01,  ..., -4.8290e+00,\n",
       "           2.7869e+01, -5.8810e+00],\n",
       "         [-5.8793e+01, -3.4719e+01, -1.9201e+01,  ..., -2.6601e+01,\n",
       "          -2.1341e+01, -2.1236e+01],\n",
       "         [-4.0065e+00, -1.3469e+01, -1.8449e+01,  ..., -2.5162e+01,\n",
       "          -2.0544e+01, -4.8323e+00],\n",
       "         ...,\n",
       "         [ 6.4058e+00, -2.7892e+00, -3.5030e+00,  ...,  1.7337e+00,\n",
       "          -9.4644e+00, -4.1983e+01],\n",
       "         [-1.4886e+01, -1.1052e+01, -2.7023e+01,  ..., -2.4032e+01,\n",
       "           1.5820e-02, -5.9685e+00],\n",
       "         [ 2.0106e+01, -1.5623e+01, -1.0765e+01,  ..., -1.0886e+00,\n",
       "           1.5182e+01,  1.4308e+01]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(b1[0].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "2486780c-ab6b-4d49-956f-6e05ba0f4593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 500, 16])"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "a1939927-fc42-45ee-b027-2ed65998d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.pred_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "7c591cb6-6b34-444e-8dce-8fe794b081ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "b144561a-b9b5-46ac-aa5f-856cc9f6cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inp = torch.zeros_like(b1[1][:, -args.pred_len:, :]).float()\n",
    "dec_inp = torch.cat([b1[1][:, :args.label_len, :], dec_inp], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "b3a2feb5-e951-41ae-95e8-bdc246cefdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 100, 16])"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "608ab679-fdd1-4fce-9f78-2e422fcfe22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 100, 16])"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "443300ac-79ce-45cc-8660-7261d4c2cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 16])"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[1][:, -args.pred_len:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "9245df13-a98c-4e3f-8e1d-fef7c948aa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 40, 16])"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[1][:, :args.label_len, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "99ed2141-fedb-4418-8bd3-e2bf349222dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 100, 4])"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[1][:,:,:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "ef5553b1-7c13-4f53-864c-3204404665ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 100, 16])"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "d2293f51-2ff8-4400-b09d-bc1c6d031e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (decomp): series_decomp(\n",
       "    (moving_avg): moving_avg(\n",
       "      (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "    )\n",
       "  )\n",
       "  (enc_embedding): DataEmbedding_wo_pos(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(16, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=512, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding_wo_pos(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(16, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=512, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (decomp1): series_decomp(\n",
       "          (moving_avg): moving_avg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp2): series_decomp(\n",
       "          (moving_avg): moving_avg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): my_Layernorm(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attention): AutoCorrelationLayer(\n",
       "          (inner_correlation): AutoCorrelation(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (decomp1): series_decomp(\n",
       "          (moving_avg): moving_avg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp2): series_decomp(\n",
       "          (moving_avg): moving_avg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (decomp3): series_decomp(\n",
       "          (moving_avg): moving_avg(\n",
       "            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "        (projection): Conv1d(512, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "    )\n",
       "    (norm): my_Layernorm(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (projection): Linear(in_features=512, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoformer.Model(args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "d6f4ed9c-4dc5-442b-b4c8-36a8a3a63f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[71.6197, 61.6116, 21.0257,  ..., 71.5852, 73.0065, 55.5396],\n",
       "         [72.8775, 63.7794, 17.5068,  ..., 74.1997, 67.0087, 56.9475],\n",
       "         [79.0788, 56.7229, 19.2600,  ..., 74.6488, 63.7263, 55.1225],\n",
       "         ...,\n",
       "         [81.0119, 62.4430, 47.9587,  ..., 71.7357, 74.6668, 70.6535],\n",
       "         [84.9704, 64.7731, 49.5155,  ..., 75.2043, 75.1146, 70.0724],\n",
       "         [59.4920, 77.6923, 48.7098,  ..., 70.8696, 46.5217, 57.5186]],\n",
       "\n",
       "        [[64.5330, 67.2606, 16.4378,  ..., 76.3374, 63.5895, 64.3684],\n",
       "         [73.6335, 60.0841, 14.4786,  ..., 80.4406, 58.5424, 62.2762],\n",
       "         [70.3385, 64.0664, 24.4106,  ..., 80.6096, 56.6966, 62.5893],\n",
       "         ...,\n",
       "         [73.3683, 64.1530, 27.1453,  ..., 87.9009, 53.7951, 73.0177],\n",
       "         [74.7011, 65.3769, 30.4544,  ..., 86.9556, 53.9701, 75.0075],\n",
       "         [65.3242, 85.1730, 13.4185,  ..., 91.0981, 49.7809, 55.8396]],\n",
       "\n",
       "        [[73.0341, 53.6389, 19.8400,  ..., 87.8904, 70.5910, 59.1613],\n",
       "         [72.4065, 58.6468, 27.5749,  ..., 87.7787, 70.9926, 59.0341],\n",
       "         [70.7088, 63.6878, 36.3018,  ..., 87.2137, 70.6285, 62.4595],\n",
       "         ...,\n",
       "         [84.6134, 66.7069, 17.2411,  ..., 86.7971, 66.8353, 52.4055],\n",
       "         [84.9409, 67.5880, 15.6311,  ..., 90.2385, 70.4585, 50.4308],\n",
       "         [88.4061, 58.1515, 20.7593,  ..., 82.2495, 57.7396, 53.5778]],\n",
       "\n",
       "        [[78.4216, 58.0209, 28.1420,  ..., 83.3858, 61.3192, 67.3907],\n",
       "         [76.1057, 64.9090, 38.6354,  ..., 82.8863, 59.5358, 72.7449],\n",
       "         [77.2411, 65.5245, 43.4159,  ..., 75.8248, 59.8728, 67.5779],\n",
       "         ...,\n",
       "         [64.6110, 66.4628, 51.7177,  ..., 60.2540, 59.0342, 78.5647],\n",
       "         [63.8933, 66.3628, 53.5836,  ..., 57.7372, 57.6277, 80.6674],\n",
       "         [62.7983, 78.5250, 26.1284,  ..., 75.7554, 57.5033, 85.7461]],\n",
       "\n",
       "        [[66.6799, 70.5406, 33.9905,  ..., 68.6236, 62.7123, 64.1514],\n",
       "         [66.7188, 71.1577, 39.3065,  ..., 59.6181, 63.7835, 57.4100],\n",
       "         [66.0703, 73.0958, 45.5277,  ..., 62.0106, 64.5194, 60.8821],\n",
       "         ...,\n",
       "         [60.6383, 60.8105, 44.5350,  ..., 61.5520, 65.2467, 79.0948],\n",
       "         [61.2149, 61.4830, 49.0556,  ..., 62.3460, 64.7170, 80.1291],\n",
       "         [69.4447, 47.3721, 23.1239,  ..., 82.0857, 46.5668, 70.6384]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(b1[0], b1[0][:,:,:4], dec_inp, b1[1][:,:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "e87aa437-0fef-4393-a1a4-00c4b71abc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(16, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=512, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(16, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=512, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (inner_attention): ProbAttention(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): ConvLayer(\n",
       "        (downConv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), padding_mode=circular)\n",
       "        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ELU(alpha=1.0)\n",
       "        (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): ProbAttention(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): ProbAttention(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Informer.Model(args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "41b928c8-fff6-4769-a6d6-125c4ded4f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0570, -0.4157, -0.1510,  ...,  0.0500,  0.3376,  0.3915],\n",
       "         [-0.0348, -0.3373, -0.2179,  ..., -0.1039,  0.2944,  0.4456],\n",
       "         [ 0.0469, -0.3929, -0.2783,  ...,  0.1064,  0.2877,  0.5842],\n",
       "         ...,\n",
       "         [-0.7475, -0.9854, -0.2337,  ...,  0.9094, -0.1976, -0.2089],\n",
       "         [-0.8493, -1.1082, -0.3114,  ...,  0.4866, -0.2084,  0.1452],\n",
       "         [-0.6693, -0.9205, -0.2268,  ...,  0.6960, -0.5058,  0.1586]],\n",
       "\n",
       "        [[-0.0638, -0.5629, -0.2790,  ...,  0.0374,  0.4097,  0.5809],\n",
       "         [ 0.1585, -0.3637, -0.1344,  ..., -0.4755,  0.1717,  0.5125],\n",
       "         [-0.0787, -0.2398, -0.0304,  ...,  0.0221,  0.3117,  0.4799],\n",
       "         ...,\n",
       "         [-0.9184, -0.9270, -0.0674,  ...,  0.2648, -0.4298, -0.2003],\n",
       "         [-0.5262, -0.9525, -0.2406,  ...,  0.3022, -0.2528, -0.4428],\n",
       "         [-0.6395, -1.0149,  0.0353,  ...,  0.5275, -0.4536, -0.2185]],\n",
       "\n",
       "        [[ 0.2208, -0.5444, -0.0981,  ...,  0.2882,  0.6022,  0.5731],\n",
       "         [-0.0925, -0.2530,  0.1887,  ...,  0.2035,  0.3432,  0.5599],\n",
       "         [ 0.0054, -0.3802, -0.0736,  ...,  0.3262,  0.5214,  0.4840],\n",
       "         ...,\n",
       "         [-0.8405, -0.9374, -0.2348,  ...,  0.5041, -0.2103, -0.1595],\n",
       "         [-0.6766, -1.1778, -0.3158,  ...,  0.5739, -0.1511,  0.2960],\n",
       "         [-0.7306, -1.0114, -0.4164,  ...,  0.4939, -0.2586, -0.0351]],\n",
       "\n",
       "        [[ 0.0891, -0.4180, -0.1813,  ..., -0.2939,  0.1120,  0.6261],\n",
       "         [-0.0016, -0.3727,  0.0265,  ...,  0.1632,  0.4347,  0.5347],\n",
       "         [-0.2126, -0.6641, -0.3131,  ...,  0.1154,  0.3904,  0.9968],\n",
       "         ...,\n",
       "         [-0.8568, -0.9397, -0.0329,  ...,  0.4934, -0.4421, -0.2958],\n",
       "         [-0.7487, -0.9445, -0.1420,  ...,  0.5311, -0.2511, -0.1871],\n",
       "         [-1.0010, -0.9671, -0.0916,  ...,  0.2060, -0.3016, -0.1617]],\n",
       "\n",
       "        [[ 0.1648, -0.5428, -0.3524,  ...,  0.4792,  0.4928,  0.5911],\n",
       "         [ 0.0688, -0.5887, -0.3683,  ...,  0.4587,  0.5139,  0.4730],\n",
       "         [ 0.0686, -0.4137, -0.5383,  ...,  0.0535,  0.3777,  0.3278],\n",
       "         ...,\n",
       "         [-0.9002, -1.0526, -0.1813,  ...,  0.2937, -0.4155, -0.4086],\n",
       "         [-0.7988, -1.2739, -0.1169,  ...,  0.8995, -0.0303,  0.0485],\n",
       "         [-0.7682, -0.8437,  0.1502,  ...,  0.4271, -0.1269,  0.0032]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(b1[0], b1[0][:,:,:4], dec_inp, b1[1][:,:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "215b66cc-9953-431f-85c8-28aa047609dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer.Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "9e0d9f68-ff60-4dbe-a626-3d5ad0ec3655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0626, -0.1851, -1.5028,  ...,  0.2717, -0.1957, -0.8799],\n",
       "         [ 0.0770, -0.3594, -0.4376,  ...,  0.0685, -0.8484, -0.9470],\n",
       "         [ 0.2978,  0.4614, -0.6564,  ..., -0.1430, -1.1055, -0.2751],\n",
       "         ...,\n",
       "         [ 0.0898, -0.3941, -0.7998,  ...,  0.3140, -0.0287,  0.2289],\n",
       "         [ 0.1967, -0.1721, -1.0142,  ...,  0.4170, -0.4950,  0.0120],\n",
       "         [ 0.1658, -0.0521,  0.3124,  ...,  1.1811, -0.5614, -0.6409]],\n",
       "\n",
       "        [[ 0.2112,  0.0224, -0.5463,  ...,  0.6994,  0.2194, -0.5117],\n",
       "         [ 0.1603,  0.0161, -0.8348,  ...,  0.0037, -1.1548, -0.1709],\n",
       "         [ 0.2592, -0.1675, -0.9611,  ..., -0.5422, -0.8645, -0.6270],\n",
       "         ...,\n",
       "         [ 0.6859,  0.1990, -0.1051,  ..., -0.2792, -0.9675,  0.1758],\n",
       "         [ 0.7582,  0.7192,  0.1024,  ...,  0.8222, -0.7673, -0.2134],\n",
       "         [ 0.0285,  0.3575, -0.4119,  ...,  0.0299, -0.2290, -0.5249]],\n",
       "\n",
       "        [[-0.3877,  0.4745, -1.1034,  ...,  0.1650, -0.7193, -0.5817],\n",
       "         [ 0.3174,  0.2920, -0.6730,  ..., -0.4626, -1.0063, -0.1258],\n",
       "         [ 0.5926, -0.2233, -0.4987,  ..., -0.2382, -1.1726, -0.4086],\n",
       "         ...,\n",
       "         [ 0.5606,  0.5344,  0.3141,  ...,  0.6323, -0.6864, -0.5832],\n",
       "         [ 0.5749,  0.7534, -0.6051,  ..., -0.1981, -1.1587, -0.4098],\n",
       "         [ 0.6734, -0.0591,  0.5375,  ...,  0.5734, -0.2330, -0.7055]],\n",
       "\n",
       "        [[-0.4699,  0.1404, -0.7876,  ..., -0.0763,  0.1626, -0.6072],\n",
       "         [ 0.1744, -0.3457, -0.2632,  ..., -0.3799, -1.3245, -0.4258],\n",
       "         [ 0.4997, -0.1005, -0.6967,  ..., -0.0592, -0.7732, -0.5485],\n",
       "         ...,\n",
       "         [-0.0295, -0.0138, -0.5280,  ..., -0.1741, -0.8444, -0.4272],\n",
       "         [ 0.6072,  0.1132,  0.0454,  ...,  0.7019, -1.1708, -0.8327],\n",
       "         [ 0.1752, -0.2378,  0.1497,  ...,  0.8110,  0.0518, -0.6932]],\n",
       "\n",
       "        [[-0.1774,  0.2037, -0.4373,  ...,  0.2739, -0.2317, -0.5856],\n",
       "         [ 0.8062,  0.1317, -0.3896,  ..., -0.4776, -0.9210, -0.5932],\n",
       "         [ 0.6283, -0.2573, -0.4665,  ...,  0.4430, -0.3619, -0.1585],\n",
       "         ...,\n",
       "         [ 0.8034,  0.1975,  0.0336,  ...,  0.7707, -0.6573, -0.6650],\n",
       "         [ 0.9374,  0.2918, -0.0774,  ...,  0.1482, -0.3284, -0.5135],\n",
       "         [-0.2307, -0.0770, -0.5435,  ...,  0.2234, -0.0486, -0.7601]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model(b1[0], b1[0][:,:,:4], dec_inp, b1[1][:,:,:4])\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "1b9e61fe-64ee-4f19-a9d0-c858324bf1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = o[:, -args.pred_len:, :]\n",
    "by = b1[1][:, -args.pred_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "5ad7d186-1f26-48a8-b944-7e30fa52b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 96, 16]) torch.Size([5, 96, 16])\n"
     ]
    }
   ],
   "source": [
    "print(o.shape, by.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "2164f3fc-1ad1-4c9e-8da0-1954ccdd6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86910383-ad2f-468c-90b4-83959ae1264a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6b88e-a4c1-4e73-a7b3-d6f1e63b09aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "8e9b8cef-0108-4c37-880b-bc5c93086c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2fd5752-a87a-4e2f-a0a5-efd873483f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9de6a17-1f0e-4f30-bcaa-11b1a5cdebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c752e33-82b6-4712-b106-6e9f66cf0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  851.3411118527677  | duration:  16324.859073162079\n",
      "Informer :  3057.6708257147607  | duration:  2242.310148715973\n"
     ]
    }
   ],
   "source": [
    "models = {'PatchTST': PatchTST, 'Informer': Informer}\n",
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}\n",
    "loss_fn = nn.MSELoss()\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(s_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(s_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "a2faa79e-fec2-41b6-b3c2-0fd55caba9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.Transformer' from '/Users/gift/github/PatchTST/PatchTST_supervised/models/Transformer.py'>"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e11f082-28dd-4e43-8822-7a9e3261fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c63b74a-4edd-4197-bb83-30de28698af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  923.2179946899414  | duration:  56.7196569442749\n",
      "Informer :  3104.5015970865884  | duration:  37.66055178642273\n"
     ]
    }
   ],
   "source": [
    "models = {'PatchTST': PatchTST, 'Informer': Informer}\n",
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('mps')\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args).to(device)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(s_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(s_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adcfc959-88e2-4c2b-8ccf-9b12f865ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  925.5157216389974  | duration:  58.14438796043396\n"
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "models = {'PatchTST': PatchTST}\n",
    "# models = {'PatchTST': PatchTST, 'Informer': Informer}\n",
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('mps')\n",
    "torch.mps.profiler.start()\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args).to(device)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(s_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(s_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)\n",
    "torch.mps.profiler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94cffced-862a-4b63-a8cb-b968896dc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b13d8b-d3c3-4504-a8d9-6faa131c056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  916.0164006551107  | duration:  58.74329495429993\n"
     ]
    }
   ],
   "source": [
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}\n",
    "torch.mps.empty_cache()\n",
    "models = {'PatchTST': PatchTST}\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('mps')\n",
    "\n",
    "torch.mps.profiler.start()\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args).to(device)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(w_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        # inputs = inputs\n",
    "        # labels = labels\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(w_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)\n",
    "torch.mps.profiler.stop()\n",
    "# torch.cuda.memory._record_memory_history(enabled=None)\n",
    "# torch.cuda.memory._dump_snapshot(f\"{file_prefix}.pickle\")\n",
    "# torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a280d3e2-df94-4822-ad3e-37ffa331837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c8624-85d2-4856-a030-6de87fba034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b26a1-005a-4b81-a8d5-81159f2d3d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d07d5f-b31b-4611-8f19-349d99e1a22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca481d-d572-413d-975b-281f5b1d53a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b0443-503f-4b23-b69b-df346b3832cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d87e4921-cb17-4781-8da0-d7c7ddebeac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 27.01 GB, other allocations: 4.82 GB, max allowed: 36.27 GB). Tried to allocate 4.73 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m dec_inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([labels[:, :args\u001b[38;5;241m.\u001b[39mlabel_len, :], dec_inp], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTST\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m m:\n\u001b[0;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# outputs = model(inputs)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs, inputs[:,:,:\u001b[38;5;241m4\u001b[39m], dec_inp, labels[:,:,:\u001b[38;5;241m4\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github/PatchTST/PatchTST_supervised/models/PatchTST.py:90\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)    \u001b[38;5;66;03m# x: [Batch, Channel, Input length]\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)    \u001b[38;5;66;03m# x: [Batch, Input length, Channel]\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github/PatchTST/PatchTST_supervised/layers/PatchTST_backbone.py:74\u001b[0m, in \u001b[0;36mPatchTST_backbone.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     71\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)                                                              \u001b[38;5;66;03m# z: [bs x nvars x patch_len x patch_num]\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m                                                                \u001b[38;5;66;03m# z: [bs x nvars x d_model x patch_num]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(z)                                                                    \u001b[38;5;66;03m# z: [bs x nvars x target_window] \u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# denorm\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github/PatchTST/PatchTST_supervised/layers/PatchTST_backbone.py:168\u001b[0m, in \u001b[0;36mTSTiEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(u \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_pos)                                         \u001b[38;5;66;03m# u: [bs * nvars x patch_num x d_model]\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m                                                      \u001b[38;5;66;03m# z: [bs * nvars x patch_num x d_model]\u001b[39;00m\n\u001b[1;32m    169\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(z, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,n_vars,z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m],z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))                \u001b[38;5;66;03m# z: [bs x nvars x patch_num x d_model]\u001b[39;00m\n\u001b[1;32m    170\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)                                                   \u001b[38;5;66;03m# z: [bs x nvars x d_model x patch_num]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github/PatchTST/PatchTST_supervised/layers/PatchTST_backbone.py:193\u001b[0m, in \u001b[0;36mTSTEncoder.forward\u001b[0;34m(self, src, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m    191\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_attention:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers: output, scores \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github/PatchTST/PatchTST_supervised/layers/PatchTST_backbone.py:258\u001b[0m, in \u001b[0;36mTSTEncoderLayer.forward\u001b[0;34m(self, src, prev, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m    256\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_ffn(src)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m## Position-wise Feed-Forward\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m src2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m## Add & Norm\u001b[39;00m\n\u001b[1;32m    260\u001b[0m src \u001b[38;5;241m=\u001b[39m src \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_ffn(src2) \u001b[38;5;66;03m# Add: residual connection with residual dropout\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tsfm/lib/python3.9/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 27.01 GB, other allocations: 4.82 GB, max allowed: 36.27 GB). Tried to allocate 4.73 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "models = {'PatchTST': PatchTST, 'Informer': Informer}\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('mps')\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args).to(device)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(w_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        # inputs = inputs\n",
    "        # labels = labels\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(w_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421dc893-21aa-4c7b-8287-d7e25f8664f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55207e68-fc31-4553-bcae-547b4e41ba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52900da-b7e1-43de-8c0a-e7428e05dfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f48c5-7825-4f55-bee4-ee1241b869ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        # if i % 1000 == 999:\n",
    "        #     last_loss = running_loss / 1000 # loss per batch\n",
    "        #     print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "        #     tb_x = epoch_index * len(training_loader) + i + 1\n",
    "        #     tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "        #     running_loss = 0.\n",
    "    avg_loss = running_loss / len(training_loader)\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46aad3a-56b9-4527-a39c-1d443ebccdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca85b1-70d3-44a4-b8ba-8ce86a38d090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990421a-7689-4164-8306-82bfe44980fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "d8a1156c-7fa8-4329-927a-71d4cf1c533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_loader import Dataset_ETT_hour as etth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b9077f46-7d9b-4192-b6e9-588816ad50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../dataset/'\n",
    "# size = [params.context_points, 0, params.target_points]\n",
    "# dls = DataLoaders(\n",
    "#         datasetCls=Dataset_ETT_hour,\n",
    "#         dataset_kwargs={\n",
    "#         'root_path': root_path,\n",
    "#         'data_path': 'ETTh2.csv',\n",
    "#         'features': params.features,\n",
    "#         'scale': True,\n",
    "#         'size': size,\n",
    "#         'use_time_features': False\n",
    "#         },\n",
    "#         batch_size=params.batch_size,\n",
    "#         workers=params.num_workers,\n",
    "#         )\n",
    "d = etth(root_path=root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "16658068-1b78-4347-bb0f-856e241d3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8161"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7d94bb28-bb7b-4d9f-91cc-19076dbbc189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "7383f8ea-57b6-4048-bf9c-353e4498721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 1), (192, 1), (384, 4), (192, 4))"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].shape, d[0][1].shape, d[0][2].shape, d[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78752f8a-d015-4416-9ccf-4f469121adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
