{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9340fe8e-77c5-4de7-bcd4-0b9c7c23f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
    "import argparse\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bfafc9-3c8b-45e8-b0cb-1a5c37466886",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 3000\n",
    "num_features = 10\n",
    "pred_len = 60\n",
    "label_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b64a65-f55c-497a-8175-22329c7ee7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.uniform(low=1, high=100, size=(time_steps, num_features))\n",
    "data_y = data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b0e9b1-bcdd-47ea-bef3-09fd0ce71ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 10), (3000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04a49a9-da33-42d3-84cf-24d3fd94f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d98238d-3ffc-4d6c-a85c-cb7981ae63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPretrainDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, num_features, time_steps=15, seq_len=96, pred_len=96, label_len=48, bs=5):\n",
    "        self.num_features = num_features\n",
    "        self.time_steps = time_steps\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.label_len = label_len\n",
    "        self.batch_size = bs\n",
    "        self.prebatch_len = seq_len + bs  - 1\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.time_steps - self.seq_len - pred_len + 1) // self.batch_size \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s_begin = self.batch_size * idx\n",
    "        s_end = s_begin + self.prebatch_len \n",
    "        # r_begin = s_end - 1 # - self.label_len\n",
    "        # r_end = r_begin + 1 # + self.pred_len  + self.label_len \n",
    "        #regression\n",
    "        # r_begin = s_begin + self.seq_len - 1\n",
    "        # r_end = r_begin + self.batch_size\n",
    "        \n",
    "        r_begin = s_begin + self.seq_len - self.label_len -1\n",
    "        r_end = r_begin + self.pred_len + self.label_len + self.batch_size - 1\n",
    "        # print(s_begin, s_end, r_begin, r_end)\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return torch.Tensor(seq_x).to(device), torch.Tensor(seq_y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d047a7a-3ef0-41d7-872c-e2ef0932d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = DummyPretrainDataset(data_x, data_y, num_features, time_steps, seq_len=500, pred_len=pred_len, label_len=label_len, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6d8b55-e85c-4a03-aa1e-65e3196a0dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([599, 10]), torch.Size([199, 10]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0][0].shape, dset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061eceab-9987-4e6f-a1d9-487fa816cfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c610b2-2621-421e-9b39-b54dcd05b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowView:\n",
    "    def __init__(self, window_size, stride, pred_len, label_len):\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.pred_len = pred_len\n",
    "        self.label_len = label_len\n",
    "    def slide_collate_fn(self, batch):\n",
    "        return batch[0].unfold(0, self.window_size, self.stride).transpose(1,2), batch[1].unfold(0, self.pred_len+self.label_len, self.stride).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7a1d2a-5bea-4da7-9d6b-16b7ff2acacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindowView(500, 1, pred_len, label_len)\n",
    "w_dl = DataLoader(dset, batch_size=None, collate_fn=sw.slide_collate_fn, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36df48a4-65a7-4b57-91ed-7674fe1f2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPretrainStackDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, num_features, time_steps=15, seq_len=6, pred_len=8, label_len=8, bs=5):\n",
    "        self.num_features = num_features\n",
    "        self.time_steps = time_steps\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.label_len = label_len\n",
    "        # self.batch_size = bs\n",
    "        # self.prebatch_len = seq_len + bs - 1\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.time_steps - self.seq_len + 1 - self.pred_len)  # // self.batch_size \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s_begin = idx\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin  + self.pred_len  + self.label_len \n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return torch.Tensor(seq_x), torch.Tensor(seq_y)\n",
    "# b1[0].float(), b1[0][:,:,:4].float(), dec_inp, b1[1][:,:,:4].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8af49fe-1684-4ecd-9657-3a767d450e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sset = DummyPretrainStackDataset(data_x, data_y, num_features, time_steps, seq_len=500, pred_len=60, label_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4070cfdf-3e00-4ccc-842e-96ea3273e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dl = DataLoader(sset, batch_size=100, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4595e46-3fa5-4225-b539-3a168b745405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18e7b55-0e4c-4b0d-a136-9b9fe6470304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(random_seed=2021, root_path='./data/ETT/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=500, label_len=40, pred_len=60, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=10, dec_in=10, c_out=10, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=100, patience=100, learning_rate=0.0001, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# random seed\n",
    "parser.add_argument('--random_seed', type=int, default=2021, help='random seed')\n",
    "\n",
    "# # basic config\n",
    "# parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
    "# parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
    "# parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
    "#                     help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# # data loader\n",
    "# parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=500, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=label_len, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=pred_len, help='prediction sequence length')\n",
    "\n",
    "\n",
    "# DLinear\n",
    "#parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "\n",
    "# PatchTST\n",
    "parser.add_argument('--fc_dropout', type=float, default=0.05, help='fully connected dropout')\n",
    "parser.add_argument('--head_dropout', type=float, default=0.0, help='head dropout')\n",
    "parser.add_argument('--patch_len', type=int, default=16, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "parser.add_argument('--padding_patch', default='end', help='None: None; end: padding on the end')\n",
    "parser.add_argument('--revin', type=int, default=1, help='RevIN; True 1 False 0')\n",
    "parser.add_argument('--affine', type=int, default=0, help='RevIN-affine; True 1 False 0')\n",
    "parser.add_argument('--subtract_last', type=int, default=0, help='0: subtract mean; 1: subtract last')\n",
    "parser.add_argument('--decomposition', type=int, default=0, help='decomposition; True 1 False 0')\n",
    "parser.add_argument('--kernel_size', type=int, default=25, help='decomposition-kernel')\n",
    "parser.add_argument('--individual', type=int, default=0, help='individual head; True 1 False 0')\n",
    "\n",
    "# Formers \n",
    "parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
    "parser.add_argument('--enc_in', type=int, default=num_features, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "parser.add_argument('--dec_in', type=int, default=num_features, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=num_features, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=100, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=100, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=100, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type3', help='adjust learning rate')\n",
    "parser.add_argument('--pct_start', type=float, default=0.3, help='pct_start')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "import random\n",
    "# random seed\n",
    "fix_seed = args.random_seed\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e11f082-28dd-4e43-8822-7a9e3261fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c63b74a-4edd-4197-bb83-30de28698af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  923.2179946899414  | duration:  56.7196569442749\n",
      "Informer :  3104.5015970865884  | duration:  37.66055178642273\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(args, s_dl):\n",
    "    models = {'PatchTST': PatchTST, 'Informer': Informer}\n",
    "    # models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "    #          'Transformer': Transformer}\n",
    "    loss_fn = nn.MSELoss()\n",
    "    device = torch.device('mps')\n",
    "    for m in models.keys():\n",
    "        args.model = models[m]\n",
    "        model = args.model.Model(args).to(device)\n",
    "        running_loss = 0.\n",
    "        optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "        start = time.time()\n",
    "        for i, data in enumerate(s_dl):\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            # Zero your gradients for every batch! \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Make predictions for this batch\n",
    "            dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "        \n",
    "            if 'Linear' in m or 'TST' in m:\n",
    "                outputs = model(inputs)\n",
    "            else: \n",
    "            # outputs = model(inputs)\n",
    "                outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "        \n",
    "            outputs = outputs[:, -args.pred_len:, :]\n",
    "            labels = labels[:, -args.pred_len:, :]\n",
    "            \n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "        \n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "        \n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "        stop = time.time()\n",
    "        avg_loss = running_loss / len(s_dl)\n",
    "        print(m, ': ', avg_loss, ' | duration: ', stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b77b2-ee7d-4692-a2bf-489aa8e39849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ec245-f1e3-4a97-b444-aacbf74d0daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adcfc959-88e2-4c2b-8ccf-9b12f865ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  925.5157216389974  | duration:  58.14438796043396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {'PatchTST': PatchTST}\n",
    "# models = {'PatchTST': PatchTST, 'Informer': Informer}\n",
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('mps')\n",
    "\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args).to(device)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(s_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(s_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94cffced-862a-4b63-a8cb-b968896dc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b13d8b-d3c3-4504-a8d9-6faa131c056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST :  916.0164006551107  | duration:  58.74329495429993\n"
     ]
    }
   ],
   "source": [
    "# models = {'PatchTST': PatchTST, 'Informer': Informer, 'Autoformer': Autoformer, 'DLinear': DLinear,\n",
    "#          'Transformer': Transformer}\n",
    "models = {'PatchTST': PatchTST}\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('mps')\n",
    "\n",
    "for m in models.keys():\n",
    "    args.model = models[m]\n",
    "    model = args.model.Model(args).to(device)\n",
    "    running_loss = 0.\n",
    "    optimizer= optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(w_dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        # inputs = inputs\n",
    "        # labels = labels\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Make predictions for this batch\n",
    "        dec_inp = torch.zeros_like(labels[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([labels[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "    \n",
    "        if 'Linear' in m or 'TST' in m:\n",
    "            outputs = model(inputs)\n",
    "        else: \n",
    "        # outputs = model(inputs)\n",
    "            outputs = model(inputs, inputs[:,:,:4], dec_inp, labels[:,:,:4])\n",
    "    \n",
    "        outputs = outputs[:, -args.pred_len:, :]\n",
    "        labels = labels[:, -args.pred_len:, :]\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "    stop = time.time()\n",
    "    avg_loss = running_loss / len(w_dl)\n",
    "    print(m, ': ', avg_loss, ' | duration: ', stop-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca481d-d572-413d-975b-281f5b1d53a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b0443-503f-4b23-b69b-df346b3832cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52900da-b7e1-43de-8c0a-e7428e05dfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f48c5-7825-4f55-bee4-ee1241b869ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        # if i % 1000 == 999:\n",
    "        #     last_loss = running_loss / 1000 # loss per batch\n",
    "        #     print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "        #     tb_x = epoch_index * len(training_loader) + i + 1\n",
    "        #     tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "        #     running_loss = 0.\n",
    "    avg_loss = running_loss / len(training_loader)\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46aad3a-56b9-4527-a39c-1d443ebccdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca85b1-70d3-44a4-b8ba-8ce86a38d090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990421a-7689-4164-8306-82bfe44980fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "d8a1156c-7fa8-4329-927a-71d4cf1c533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_loader import Dataset_ETT_hour as etth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b9077f46-7d9b-4192-b6e9-588816ad50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../dataset/'\n",
    "# size = [params.context_points, 0, params.target_points]\n",
    "# dls = DataLoaders(\n",
    "#         datasetCls=Dataset_ETT_hour,\n",
    "#         dataset_kwargs={\n",
    "#         'root_path': root_path,\n",
    "#         'data_path': 'ETTh2.csv',\n",
    "#         'features': params.features,\n",
    "#         'scale': True,\n",
    "#         'size': size,\n",
    "#         'use_time_features': False\n",
    "#         },\n",
    "#         batch_size=params.batch_size,\n",
    "#         workers=params.num_workers,\n",
    "#         )\n",
    "d = etth(root_path=root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "16658068-1b78-4347-bb0f-856e241d3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8161"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7d94bb28-bb7b-4d9f-91cc-19076dbbc189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "7383f8ea-57b6-4048-bf9c-353e4498721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 1), (192, 1), (384, 4), (192, 4))"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].shape, d[0][1].shape, d[0][2].shape, d[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78752f8a-d015-4416-9ccf-4f469121adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
